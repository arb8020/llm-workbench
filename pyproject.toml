[tool.uv.workspace]
members = ["bifrost", "broker", "rollouts"]

[tool.uv]
required-environments = [
    "sys_platform == 'linux' and platform_machine == 'x86_64'",
    "sys_platform == 'darwin' and platform_machine == 'arm64'"
]
conflicts = [
    [
        { extra = "interp" },
        { extra = "outlier" }
    ]
]

[project]
name = "llm-workbench"
version = "0.1.0"
description = "Complete toolkit for GPU-accelerated machine learning workflows"
requires-python = ">=3.10"

# Default: Core tools only (no ML dependencies to avoid conflicts)
dependencies = [
    "rollouts",
    "broker",
    "bifrost"
]

[project.optional-dependencies]
# Interpretability support via engine (temporarily disabled for tau-bench testing)
# interp = ["engine[interp] @ file://./engine"]

manual_ndif = [
    "rollouts",
    "broker",
    "bifrost",
    # Web server
    "fastapi>=0.110.0",
    "uvicorn>=0.23.0",
    "pydantic>=2.0.0",
    # NNsight + ML stack
    "nnsight>=0.4",
    "transformers>=4.40.0",
    "torch>=2.4.0,<=2.7.1",
    "triton>=3.0.0,<=3.3.1; sys_platform == 'linux'",
    "accelerate>=0.20.0",
    "datasets>=4.0.0",
    "huggingface-hub>=0.34.4",
    "numpy<2.0.0",
    "requests>=2.28.0"
]
# Lightweight local development - no ML dependencies
local = [
    "rollouts",
    "broker", 
    "bifrost"
]

# Outlier analysis features - compatible with vLLM constraints
outlier = [
    "rollouts",
    "broker", 
    "bifrost",
    "nnsight>=0.4",
    "transformers @ git+https://github.com/huggingface/transformers.git",
    "torch>=2.4.0,<=2.7.1",  # Align with vLLM's torch requirements
    "accelerate>=0.20.0",
    "datasets>=4.0.0",
    "pyarrow>=21.0.0",
    "triton>=3.0.0,<=3.3.1; sys_platform == 'linux'",  # Compatible with vLLM's torch versions
    "huggingface-hub>=0.34.4",
    "numpy<2.0.0",
    "requests>=2.28.0",
    "pathlib"
]

# GSM8K remote vLLM example dependencies
examples_gsm8k_remote = [
    "rollouts",
    "broker", 
    "bifrost",
    # Rollouts dependencies (to ensure proper installation on remote)
    "anthropic>=0.25.0",
    "openai>=1.0.0",
    "aiohttp>=3.9.0",
    "dacite>=1.8.0",
    "pandas>=2.0.0",
    # vLLM and ML dependencies
    "vllm>=0.6.0",
    "torch>=2.4.0,<=2.7.1",  # Explicit constraint matching vLLM requirements
    "triton>=3.0.0,<=3.3.1; sys_platform == 'linux'",  # Explicit triton constraint
    "transformers>=4.40.0",
    "datasets>=4.0.0",
    "requests>=2.28.0"
]

# NNsight single-pass server deploy + smoke test
examples_gsm8k_remote_nnsight = [
    "rollouts",
    "broker",
    "bifrost",
    # Web server
    "fastapi>=0.110.0",
    "uvicorn>=0.23.0",
    "pydantic>=2.0.0",
    # NNsight + ML stack
    "nnsight>=0.4",
    "transformers>=4.40.0",
    "torch>=2.4.0,<=2.7.1",
    "triton>=3.0.0,<=3.3.1; sys_platform == 'linux'",
    "accelerate>=0.20.0",
    "datasets>=4.0.0",
    "huggingface-hub>=0.34.4",
    "numpy<2.0.0",
    "requests>=2.28.0",
    # CLI plotting utility for local activation visualization
    "plotext>=5.2.8"
]

# Emotion prefix GSM8K experiment (rollouts + NNsight server copy)
examples_emotion_prefix_gsm8k = [
    "rollouts",
    "broker",
    "bifrost",
    # Web server
    "fastapi>=0.110.0",
    "uvicorn>=0.23.0",
    "pydantic>=2.0.0",
    # NNsight + ML stack
    "nnsight>=0.4",
    "transformers>=4.40.0",
    "torch>=2.4.0,<=2.7.1",
    "triton>=3.0.0,<=3.3.1; sys_platform == 'linux'",
    "accelerate>=0.20.0",
    "datasets>=4.0.0",
    "huggingface-hub>=0.34.4",
    "numpy<2.0.0",
    "requests>=2.28.0",
    # Convenience
    "pyyaml>=6.0",
    "tqdm>=4.66.0"
]

# Alias with hyphens for environments that normalize extras keys
examples-emotion-prefix-gsm8k = [
    "rollouts",
    "broker",
    "bifrost",
    "fastapi>=0.110.0",
    "uvicorn>=0.23.0",
    "pydantic>=2.0.0",
    "nnsight>=0.4",
    "transformers>=4.40.0",
    "torch>=2.4.0,<=2.7.1",
    "triton>=3.0.0,<=3.3.1; sys_platform == 'linux'",
    "accelerate>=0.20.0",
    "datasets>=4.0.0",
    "huggingface-hub>=0.34.4",
    "numpy<2.0.0",
    "requests>=2.28.0",
    "pyyaml>=6.0",
    "tqdm>=4.66.0"
]

# Tau-bench variation experiment dependencies  
examples-tau-bench = [
    "rollouts",
    "broker",
    "bifrost", 
    # Rollouts dependencies
    "anthropic>=0.25.0",
    "openai>=1.0.0",
    "aiohttp>=3.9.0",
    "dacite>=1.8.0",
    "pandas>=2.0.0",
    # vLLM dependencies
    "vllm>=0.6.0", 
    "torch>=2.4.0,<=2.7.1",
    "triton>=3.0.0,<=3.3.1; sys_platform == 'linux'",
    "transformers>=4.40.0",
    "requests>=2.28.0",
    # Tau-bench specific
    "tau-bench @ git+https://github.com/sierra-research/tau-bench.git"
]

[tool.uv.sources]
rollouts = { workspace = true }
broker = { workspace = true }
bifrost = { workspace = true }

[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[tool.setuptools.packages.find]
where = ["."]
include = ["shared*"]  # Include shared module for outlier analysis
